model:
  model_type: 'entrep'
  text_encoder_type: 'clip'
  vision_encoder_type: 'dinov2'
  model_name: 'dinov2_vitb14'
  feature_dim: 768
  dropout: 0.1
  dropout_rate: 0.3
  num_classes: 4
  freeze_backbone: false
  
  # QUAN TRỌNG: Load pretrained checkpoint
  checkpoint: 'pretrained/entrep_vit_b'
  vision_checkpoint: null
  text_checkpoint: null
  
  # QUAN TRỌNG: pretrained = true để sử dụng pretrained weights
  pretrained: true
  
  logit_scale_init_value: 0.07

# Dataset configuration
dataset:
  dataset_name: 'entrep'
  dataset_type: 'contrastive'
  data_root: 'local_data/entrep'
  model_type: 'entrep'
  batch_size: 32
  num_workers: 4
  tokenizer_name: 'openai/clip-vit-base-patch32'

# Training configuration
training:
  num_epochs: 100
  val_every: 1
  save_every: 5
  use_amp: true
  plot_every: 5

# Optimizer configuration
optimizer:
  type: 'adamw'
  lr: 1e-5  # Lower learning rate for finetuning pretrained model
  weight_decay: 0.01
  betas: [0.9, 0.999]

# Learning rate scheduler
scheduler:
  type: 'cosine'
  T_max: 100
  eta_min: 1e-6

# Loss configuration
loss:
  type: 'contrastive'

# Experiment settings
experiment:
  seed: 42
  output_dir: './checkpoints/entrep_vitb_pretrained'
  use_wandb: false
  wandb_project: 'entrep-vitb-pretrained'

